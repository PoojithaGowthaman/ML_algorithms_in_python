{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some quick notes on Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We assume a linear relationship between the predictors and the response variable we are trying to predict.\n",
    "\n",
    "* p-value : the probability at which an observed difference could have occurred by just random chance.\n",
    "\n",
    "* Lower the p-value, the more important is the variable at predicting the response variable. In common terms, the let's say we are trying to see if square area is an important predictor for the price of the house. The square_area variable follows a some probability distribution, most easily the standard normal. We have most of the values in the high density area of the distribution and few values on the tails. \n",
    "\n",
    "\n",
    "* The lower the p-value, the greater the statistical significance of the observed difference.\n",
    "\n",
    "\n",
    "**MORE TO FOLLOW**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def linear_regression(x,y, iterations = 100, learning_rate = 0.01):\n",
    "    n,m = len(x[0]), len(x)\n",
    "    beta_0, beta_i = initialize_params(n)\n",
    "    for i in range(iterations):\n",
    "        gradiant_beta_0, gradient_beta_i = compute_gradient(\n",
    "        x, t, beta_0, beta_other, n, m)\n",
    "        \n",
    "        beta_0, beta_i = update_params(\n",
    "        beta_0, beta_other, gradient_beta_0, gradient_beta_i,learning_rate)\n",
    "        \n",
    "        return beta_0, beta_i\n",
    "\n",
    "    \n",
    "# setting up initial parameters\n",
    "def initialize_params(dimensions):\n",
    "    beta_0 = 0\n",
    "    beta_i = [random.random() for i in range(dimensions)]\n",
    "    return beta_0, beta_i \n",
    "\n",
    "# computing the gradients and coefficients \n",
    "\n",
    "def compute_gradient(x,y,beta_0, beta_i, dimensions, m):\n",
    "    gradient_beta_0, gradient_beta_i = 0, [0]*dimensions\n",
    "    \n",
    "    for i in range(m):\n",
    "        y_i_predicted = sum(x[i][j] * beta_other[j]\n",
    "                           fir j in range(dimensions)) + beta_0\n",
    "        derror_dy = 2* (y[i] - y_i_predicted)\n",
    "        \n",
    "        for j in range(dimensions):\n",
    "            gradient_beta_0 += derror_dy/n # gradient of average over all data points\n",
    "            \n",
    "    return gradient_beta_0, gradient_beta_i\n",
    "# update parameters\n",
    "\n",
    "def update_params(beta_0, beta_i, gradient_beta_0, gradient_beta_i, learning_rate):\n",
    "    beta_0 += gradient_beta_0 * learning_rate\n",
    "    \n",
    "    for i in range(len(beta_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
